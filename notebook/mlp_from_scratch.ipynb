{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The forward and backward passes"
      ],
      "metadata": {
        "id": "lK6Yxi0BfyUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GutTV6kjJPtS"
      },
      "outputs": [],
      "source": [
        "import math, os, time, shutil, torch, matplotlib as mpl, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import tensor\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import test_close\n",
        "torch.manual_seed(42)\n",
        "\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
        "np.set_printoptions(precision=2, linewidth=125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvr1tvjvNX1c"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transform to convert images to tensors and flatten them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert to tensor and normalize to [0, 1]\n",
        "    transforms.Lambda(lambda x: x.view(-1)) # Flatten to 784 pixels\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Extract data and labels as tensors\n",
        "x_train, y_train = zip(*mnist_train)\n",
        "x_valid, y_valid = zip(*mnist_test)\n",
        "\n",
        "# Convert to tensors\n",
        "x_train = torch.stack(x_train) # Combines images into a single tensor.\n",
        "y_train = torch.tensor(y_train)\n",
        "x_valid = torch.stack(x_valid)\n",
        "y_valid = torch.tensor(y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fundations Version\n",
        "\n",
        "## Basic architecture"
      ],
      "metadata": {
        "id": "e6IcjMIWfuWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "print(f\"Training samples: {n}\\nNumber of pixels: {m}\\nNumber of possible outcome: {c}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_yLQlDZe5uB",
        "outputId": "f249f6bd-b553-4721-8ce5-8ddbbd2d9ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 60000\n",
            "Number of pixels: 784\n",
            "Number of possible outcome: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num hidden\n",
        "nh = 50"
      ],
      "metadata": {
        "id": "k8B0CqrMgRHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.randn(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh, 1) # We are leaving at one output because we will be using MSE for now, this me we will just output what number we think it is from 0 - 10. This is only for simplicity.\n",
        "b2 = torch.zeros(1)"
      ],
      "metadata": {
        "id": "auOwYDMgiMGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear layer\n",
        "def lin(x, w, b):\n",
        "  return x@w + b"
      ],
      "metadata": {
        "id": "VUO7kzf3iomN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = lin(x_valid, w1, b1)\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzUfBijHoJsd",
        "outputId": "5895e0fe-8317-46f0-afdf-fa7d62527681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return x.clamp_min(0.)"
      ],
      "metadata": {
        "id": "jceQJ3sVofTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = relu(t)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syfJgmAEor4j",
        "outputId": "8ca2ed34-c9cc-436c-c58c-36fc6223eda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.29,  2.50,  0.00,  ...,  0.00,  2.37, 13.58],\n",
              "        [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  6.45],\n",
              "        [ 0.00,  3.45,  0.00,  ...,  6.08,  4.49,  4.17],\n",
              "        ...,\n",
              "        [ 5.17, 12.24,  0.00,  ..., 14.33,  1.39, 25.14],\n",
              "        [ 5.17,  4.77, 10.26,  ...,  8.97,  6.15, 15.86],\n",
              "        [ 2.73,  0.00,  9.40,  ..., 10.27,  0.00, 21.07]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating MLP from scratch\n",
        "def model(xb):\n",
        "  l1 = lin(xb, w1, b1)\n",
        "  l2 = relu(l1)\n",
        "  return lin(l2, w2, b2)"
      ],
      "metadata": {
        "id": "yrXp71xcouh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model(x_valid)\n",
        "res.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2fL2KXRp9f7",
        "outputId": "5a30dc09-d076-40fd-c9a3-36a5a45dc67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function: MSE\n",
        "\n",
        "(`mse` is not a suitable loss function for multi-class classification; We'll use `mse` for now to keep things simple.)"
      ],
      "metadata": {
        "id": "Sm0ZBvZNr-mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.shape, y_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ECQE9ZqCHo",
        "outputId": "1b319ea4-d32c-4aa1-d15d-bc171e361b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10000, 1]), torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting\n",
        "\n",
        "# We can either remove the column or we add a column\n",
        "\n",
        "(res.squeeze() - y_valid).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WX-oC26TOOr",
        "outputId": "88c313f7-7cad-4f50-b5b2-acc16b98b2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, y_valid = y_train.long(), y_valid.long()\n",
        "\n",
        "preds = model(x_train)\n",
        "preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQiUbUeLUV9h",
        "outputId": "063678b5-0cf1-4c9f-927c-2a1b8d4cd002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(output, target):\n",
        "  return ((output[:,0] - target)**2).mean()"
      ],
      "metadata": {
        "id": "aHpop14CVs-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(preds, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z54hj07WV9F",
        "outputId": "2aac974a-c247-4ffa-8df6-fe2bf5349323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4314.73)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient and backward pass"
      ],
      "metadata": {
        "id": "ExfLLMK8WraO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import symbols, diff\n",
        "x, y = symbols('x y')\n",
        "diff(x**2, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "JTUU6rbmWjXl",
        "outputId": "879b9a56-c21f-4e87-964a-1fc82059b414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2*x"
            ],
            "text/latex": "$\\displaystyle 2 x$"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff(3*x**2+9, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "RdBAzsY9W6qO",
        "outputId": "fbd7a307-d243-4f0b-b9b4-8731a32cc586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6*x"
            ],
            "text/latex": "$\\displaystyle 6 x$"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "  # grad of matmul with respect to input\n",
        "  inp.g = out.g @ w.t() # gradient w.r.t input. Output: [n, in_features]\n",
        "  w.g = inp.t()@out.g # gradient for weights. Output: [in_features, out_features]\n",
        "  b.g = out.g.sum(0) # gradient for bias. Output: [out_features]"
      ],
      "metadata": {
        "id": "Bfl6fCNCbTsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function calculates gradients of the loss with respect to `inp`, `w`, and `b` using the chain rule, given the gradient of the loss with respect to `out` (storted as `out.g`)."
      ],
      "metadata": {
        "id": "mnpwhMztuvRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "  # forward pass:\n",
        "  l1 = lin(inp, w1, b1)\n",
        "  l2 = relu(l1)\n",
        "  out = lin(l2, w2, b2)\n",
        "  diff = out[:,0]-targ # Extracts the first column of out([n]), subtracts targ([n]), resulting in [n]\n",
        "  loss = diff.pow(2).mean() # Compute MSE\n",
        "\n",
        "  # Backward pass: compures gradients of the loss w.r.t. all parameters (w1, b1, w2, b2) and inputs (inp, l1, l2) using the chain rule.\n",
        "  out.g = 2.*diff[:, None]/ inp.shape[0] # Gradient of loss w.r.t output. diff[:, None] adds a dimension for broadcasting, matching out's shape\n",
        "  # Propagates gradients backward through the second linear layer, ReLU, and first linear layer using the chain rule\n",
        "  lin_grad(l2, out, w2, b2)\n",
        "  l1.g = (l1>0).float() * l2.g\n",
        "  lin_grad(inp, l1, w1, b1)"
      ],
      "metadata": {
        "id": "3NdmO3shihcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "metadata": {
        "id": "wPlq1BBjf9jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grad(x): return x.g.clone()\n",
        "chks = w1,w2,b1,b2,x_train\n",
        "grads = w1g,w2g,b1g,b2g,ig = tuple(map(get_grad, chks))"
      ],
      "metadata": {
        "id": "1jnj3wEwgA1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mkgrad(x): return x.clone().requires_grad_(True)\n",
        "ptgrads = w12,w22,b12,b22,xt2 = tuple(map(mkgrad, chks))"
      ],
      "metadata": {
        "id": "0U-OXbU7hkCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(inp, targ):\n",
        "  l1 = lin(inp, w12, b12)\n",
        "  l2 = relu(l1)\n",
        "  out = lin(l2, w22, b22)\n",
        "  return mse(out, targ)"
      ],
      "metadata": {
        "id": "IvAg1COym3P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = forward(xt2, y_train)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "7YU16WMZnUip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in zip(grads, ptgrads):\n",
        "  test_close(a, b.grad, eps=0.01)"
      ],
      "metadata": {
        "id": "5HM_eleanavl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refactor model\n",
        "\n",
        "## Layers as classes"
      ],
      "metadata": {
        "id": "QY_bEWvowY7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu():\n",
        "  def __call__(self, inp):\n",
        "    self.inp = inp\n",
        "    self.out = inp.clamp_min(0.)\n",
        "    return self.out\n",
        "\n",
        "  def backward(self):\n",
        "    self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "metadata": {
        "id": "34oR08Efnids"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lin():\n",
        "  def __init__(self, w, b):\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "\n",
        "  def __call__(self, inp):\n",
        "    self.inp = inp\n",
        "    self.out = lin(inp, self.w, self.b)\n",
        "    return self.out\n",
        "\n",
        "  def backward(self):\n",
        "    self.inp.g = self.out.g @ self.w.t()\n",
        "    self.w.g = self.inp.t() @ self.out.g\n",
        "    self.b.g = self.out.g.sum(0)"
      ],
      "metadata": {
        "id": "4zv5vsy_xY3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mse():\n",
        "  def __call__(self, inp, targ):\n",
        "    self.inp = inp\n",
        "    self.targ = targ\n",
        "    self.out = mse(inp, targ)\n",
        "    return self.out\n",
        "\n",
        "  def backward(self):\n",
        "    self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "metadata": {
        "id": "QIrL1vFTjrtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "  def __init__(self, w1, b1, w2, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    self.loss = Mse()\n",
        "\n",
        "  def __call__(self, x, targ):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return self.loss(x, targ)\n",
        "\n",
        "  def backward(self):\n",
        "    self.loss.backward()\n",
        "    for l in reversed(self.layers):\n",
        "      l.backward()"
      ],
      "metadata": {
        "id": "kONFh9jtlnvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(w1, b1, w2, b2)"
      ],
      "metadata": {
        "id": "i86tQWPAqnF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model(x_train, y_train)"
      ],
      "metadata": {
        "id": "Ik_5gO6UqrtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.backward()"
      ],
      "metadata": {
        "id": "V9_PXdcaqvZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(w2g, w2.g, eps=0.01)\n",
        "test_close(b2g, b2.g, eps=0.01)\n",
        "test_close(w1g, w1.g, eps=0.01)\n",
        "test_close(b1g, b1.g, eps=0.01)\n",
        "test_close(ig, x_train.g, eps=0.01)"
      ],
      "metadata": {
        "id": "mbHiLDdiqxMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module.forward()"
      ],
      "metadata": {
        "id": "M0yiwFNcDCae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Module():\n",
        "  def __call__(self, *args):\n",
        "    self.args = args\n",
        "    self.out = self.forward(*args)\n",
        "    return self.out\n",
        "\n",
        "  def forward(self):\n",
        "    raise Exception('not implemented')\n",
        "  def backward(self):\n",
        "    self.bwd(self.out, *self.args)\n",
        "  def bwd(self):\n",
        "    raise Exception('not implemented')"
      ],
      "metadata": {
        "id": "7IJAWJ_H0HrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu(Module):\n",
        "  def forward(self, inp):\n",
        "    return inp.clamp_min(0.)\n",
        "  def bwd(self, out, inp):\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "metadata": {
        "id": "sHCJk85y11nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lin(Module):\n",
        "  def __init__(self, w, b):\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "  def forward(self, inp):\n",
        "    return inp @ self.w + self.b\n",
        "  def bwd(self, out, inp):\n",
        "    inp.g = self.out.g @ self.w.t()\n",
        "    self.w.g = inp.t() @ self.out.g\n",
        "    self.b.g = self.out.g.sum(0)"
      ],
      "metadata": {
        "id": "QegP9flUF8sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mse(Module):\n",
        "  def forward (self, inp, targ):\n",
        "    return (inp.squeeze() - targ).pow(2).mean()\n",
        "  def bwd(self, out, inp, targ):\n",
        "    inp.g = 2 *(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "metadata": {
        "id": "a6Bb8UxLGm8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(w1, b1, w2, b2)"
      ],
      "metadata": {
        "id": "533zCNDGHkQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model(x_train, y_train)"
      ],
      "metadata": {
        "id": "66y9OqfJHnee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.backward()"
      ],
      "metadata": {
        "id": "OHOT_qaMHpXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(w2g, w2.g, eps=0.01)\n",
        "test_close(b2g, b2.g, eps=0.01)\n",
        "test_close(w1g, w1.g, eps=0.01)\n",
        "test_close(b1g, b1.g, eps=0.01)\n",
        "test_close(ig, x_train.g, eps=0.01)"
      ],
      "metadata": {
        "id": "p6OFD5_OHrjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd"
      ],
      "metadata": {
        "id": "2qrFdZj4ILpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear(nn.Module):\n",
        "  def __init__(self, n_in, n_out):\n",
        "    super().__init__()\n",
        "    self.w = torch.randn(n_in, n_out).requires_grad_()\n",
        "    self.b = torch.zeros(n_out).requires_grad_()\n",
        "  def forward(self, inp):\n",
        "    return inp@self.w + self.b"
      ],
      "metadata": {
        "id": "XiJJXuc7J3xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [Linear(n_in, nh), nn.ReLU(), Linear(nh, n_out)]\n",
        "\n",
        "  def __call__(self, x, targ):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return F.mse_loss(x, targ[:,None])"
      ],
      "metadata": {
        "id": "RUAIak9WK79o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(m, nh, 1)\n",
        "loss = model(x_train, y_train)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "rCaA_DDrMJ3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l0 = model.layers[0]\n",
        "l0.b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VshZW8LyMbi2",
        "outputId": "5e06dc44-30a5-459d-91ca-43cbd61cfacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-19.69,  -2.37,  -0.11,   1.99,  12.68, -15.26, -18.45,   0.34,   3.74,  14.70,  10.83,  12.20,  -2.92, -28.14,\n",
              "          0.76,  69.35, -22.03,  49.92,  -7.11,   1.41,  25.15,  11.33, -17.96, -13.17, -17.67, -10.45,  -0.10, -18.96,\n",
              "        -34.67,  -0.82,  40.97,   4.43,  62.47,  31.72,  55.54,  45.16,   3.19,  12.82,  12.32,  -1.42,   4.51,  -6.06,\n",
              "        -62.45,  -1.84,  -1.40,   7.05,   0.47,  18.77,  -4.73,  -6.43])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minibatch_training"
      ],
      "metadata": {
        "id": "5pSQhgHgNPGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "metadata": {
        "id": "wmBsLHdq4t5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BCa6EgdL5AFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHUQHpLd5jB9",
        "outputId": "cb8c6d63-ebac-460a-cbf0-48665c502155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross entropy loss"
      ],
      "metadata": {
        "id": "UNJAkWRrm_dp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$$\n",
        "\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ],
      "metadata": {
        "id": "iE9KQG-GnC3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def log_softmax(x):\n",
        "#   return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
      ],
      "metadata": {
        "id": "rdgIVt5vm6KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simplification when we compute the log softmax:\n",
        "# def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ],
      "metadata": {
        "id": "b4COHCwXRSQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$."
      ],
      "metadata": {
        "id": "ZXp8KV0oUXJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "metadata": {
        "id": "TwBJcHSPStgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us.\n",
        "\n",
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "metadata": {
        "id": "04v64NN1UrKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
        "sm_pred = log_softmax(pred)\n",
        "sm_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM0qYt5NU8AX",
        "outputId": "e3afa70d-a27a-45e6-b29c-7cbef35bfbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
              "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
              "        [-2.34, -2.32, -2.14,  ..., -2.44, -2.48, -2.14],\n",
              "        ...,\n",
              "        [-2.34, -2.28, -2.17,  ..., -2.38, -2.43, -2.14],\n",
              "        [-2.36, -2.33, -2.18,  ..., -2.43, -2.37, -2.20],\n",
              "        [-2.38, -2.28, -2.22,  ..., -2.43, -2.41, -2.19]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross entropy loss ofr some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
      ],
      "metadata": {
        "id": "dEQlQuTHXD-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CinnNaSWVR7u",
        "outputId": "d3dd2e27-da0a-41f1-e852-46bf62351f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[0,5],sm_pred[1,0],sm_pred[2,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujx7ZxOZX5I9",
        "outputId": "e31fc4c8-2111-4b76-b568-118ecf5f7482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
              " tensor(-2.14, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_pred[[0, 1, 2], y_train[:3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQVLZoa2aFdZ",
        "outputId": "19346ea3-d741-4e89-d6c6-3db5abfd9d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.40, -2.37, -2.14], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
      ],
      "metadata": {
        "id": "EiqxomE08lj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(input, target):\n",
        "  return -input[range(target.shape[0]), target].mean()"
      ],
      "metadata": {
        "id": "b7ks54biYYsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nll(sm_pred, y_train)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HYDOvRgY2CU",
        "outputId": "b9812cc1-8f56-42f9-c636-163675818dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then use PyTorch's implementation. `negative likelihood loss`"
      ],
      "metadata": {
        "id": "5b_ygf1b86Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
      ],
      "metadata": {
        "id": "Ye53UoV-ZXak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
      ],
      "metadata": {
        "id": "_s8uhW_B91Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
      ],
      "metadata": {
        "id": "464rSUxN90zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic training loop\n",
        "\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "\n",
        "*   get the output of the model on a batch of inputs\n",
        "*   compare the output to the labels we have and compute a loss\n",
        "*  calculate the gradients of the loss with respect to every paremeter of the model\n",
        "*  update said parameters with those gradients to make them a little bit better\n",
        "\n"
      ],
      "metadata": {
        "id": "a3LjXF0qCcta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "metadata": {
        "id": "hfKI98orCcA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 50             # batch size\n",
        "\n",
        "\n",
        "xb = x_train[0:bs]  # a mini-batch from x\n",
        "preds = model(xb)   # predictions\n",
        "preds[0], preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIhusw7k-Qzt",
        "outputId": "5c049630-e75c-4d94-8248-160f6ff9f528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.05,  0.03,  0.22,  0.02,  0.00, -0.09, -0.04, -0.12, -0.16,  0.20], grad_fn=<SelectBackward0>),\n",
              " torch.Size([50, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb = y_train[0:bs]\n",
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5aDxWHHD4yX",
        "outputId": "a075cb6d-4d15-4391-8082-7ab2d9f906fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7,\n",
              "        6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAGhIJO0EVc_",
        "outputId": "587a84ce-8e7b-474c-a7f2-9beb0644cd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.28, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11WCmBeeFX2h",
        "outputId": "49d3e6ff-86c5-41b0-9d9e-a3605d21081f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 4, 2, 2, 9, 2, 2, 1, 9, 9, 9, 2, 2, 1, 2, 2, 2, 9, 9, 2, 2, 9, 2, 2, 2, 2, 2, 2, 1, 9, 1, 2, 2, 2, 9, 2, 9, 2,\n",
              "        9, 9, 2, 9, 2, 9, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(out, yb):\n",
        "  return (out.argmax(dim=1)==yb).float().mean()"
      ],
      "metadata": {
        "id": "y9K1DQ9uGaLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c-LhjDUG9k6",
        "outputId": "625cd7d1-577e-4572-ee2e-6b20a377f0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.16)"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "z_Azyi3sHBGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(loss, preds, yb):\n",
        "  print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
      ],
      "metadata": {
        "id": "rR0qa9J8IYT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = x_train[:bs], y_train[:bs]\n",
        "preds = model(xb)\n",
        "report(loss_func(preds, yb), preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaKteMrLIy0h",
        "outputId": "d86b7b27-c823-4834-f902-fef593ffaa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.28, 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0, n, bs):\n",
        "    s = slice(i, min(n, i+bs))\n",
        "    xb, yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias   -= l.bias.grad   * lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9YPKglwMxSW",
        "outputId": "a9c1d57d-bdae-4259-9ce5-38e65989b562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04, 1.00\n",
            "0.02, 1.00\n",
            "0.01, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1658761e"
      },
      "source": [
        "Here's a list of everything we did in this notebook:\n",
        "\n",
        "- Loaded the MNIST dataset and prepared the data for training.\n",
        "- Built a simple two-layer neural network (MLP) from scratch using basic PyTorch operations.\n",
        "- Implemented the forward and backward passes manually for the MLP.\n",
        "- Compared the manually calculated gradients with PyTorch's autograd to verify correctness.\n",
        "- Refactored the model by creating classes for layers (`Relu`, `Lin`, `Mse`, and `Model`) to make the code more modular and object-oriented.\n",
        "- Further refactored the layer classes to inherit from a base `Module` class, mimicking PyTorch's `nn.Module`.\n",
        "- Replaced the custom layers with PyTorch's built-in `nn.Linear` and `nn.ReLU` to leverage autograd.\n",
        "- Switched from Mean Squared Error (MSE) loss to Cross-Entropy loss, which is more suitable for multi-class classification problems like MNIST.\n",
        "- Implemented and tested the `log_softmax` and `logsumexp` functions, and compared them with PyTorch's implementations.\n",
        "- Introduced the concept of negative likelihood loss (`nll`) and verified it against PyTorch's `F.nll_loss` and `F.cross_entropy`.\n",
        "- Set up a basic training loop with mini-batches.\n",
        "- Implemented an accuracy metric to evaluate the model's performance.\n",
        "- Performed a basic training run using the implemented training loop, loss function, and optimizer (manual gradient updates)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using parameters and optim"
      ],
      "metadata": {
        "id": "p_q4h08EGDRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "ZXdrI4iXGH98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l2(self.relu(self.l1(x)))"
      ],
      "metadata": {
        "id": "ogEzmpOXJhAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(m, nh, 10)\n",
        "model.l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIVkDj2GIHhL",
        "outputId": "3ba09201-bc9c-49c5-9aaa-4edab068626d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E60JkVTIPXd",
        "outputId": "ac8e3f4a-a7be-4654-a848-14d4014a2e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f'{name}: {l}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ox8px5cLKSz",
        "outputId": "6743b308-4200-473a-ad91-95c77cab4349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n",
            "relu: ReLU()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.parameters():\n",
        "  print(p.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpD26OOeLlTf",
        "outputId": "bec40c62-81fa-4cfa-b27b-8144e4618176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "      s = slice(i, min(n, i+bs))\n",
        "      xb, yb = x_train[s], y_train[s]\n",
        "      preds = model(xb)\n",
        "      loss = loss_func(preds, yb)\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "        model.zero_grad()\n",
        "    report(loss, preds, yb)"
      ],
      "metadata": {
        "id": "NOddKFk-L22m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Bm_lhoRV-P",
        "outputId": "daabcdae-cf41-47f0-ad61-6bdd1ba236f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09, 0.96\n",
            "0.04, 1.00\n",
            "0.03, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does it automatically determine the layers and parameters?\n",
        "\n",
        "**Let's break it down.**\n",
        "\n",
        "Behind the scenes. PyTorch overides the `__setattr__` function in `nn.Module` so that the submodules we define are properly registered as parameters of the model."
      ],
      "metadata": {
        "id": "Lg660JIBVqrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModule():\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "\n",
        "  def __setattr__(self, k, v):\n",
        "    if not k.startswith(\"_\"):\n",
        "      self._modules[k] = v\n",
        "    super().__setattr__(k, v)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'{self._modules}'\n",
        "\n",
        "  def parameters(self):\n",
        "    for l in self._modules.values():\n",
        "      yield from l.parameters()"
      ],
      "metadata": {
        "id": "7PATU-_iVYGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = MyModule(m, nh, 10)\n",
        "mdl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuDXWJgYqHdL",
        "outputId": "b825dd51-e729-4325-d46c-3bffa7095417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in mdl.parameters():\n",
        "  print(p.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TF5eknjqRtr",
        "outputId": "f818a3f8-373d-40d9-a581-6d3d9a71fd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Registering modules"
      ],
      "metadata": {
        "id": "rVZNYllZuKr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce"
      ],
      "metadata": {
        "id": "I_kSKV8cq1vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
      ],
      "metadata": {
        "id": "i1mSVpAjuU2x",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6e98c7ed-d244-4e7f-e22f-fea09c06d8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1906846835.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i, l in enumerate(self.layers):\n",
        "      self.add_module(f'layer_{i}', l)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return reduce(lambda val, layer: layer(val), self.layers, x)"
      ],
      "metadata": {
        "id": "8vFgFl_kukQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGmuYp0Xvfg0",
        "outputId": "3775ba3b-df33-4576-e548-e20d1a958553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.ModuleList**\n",
        "\n",
        "`nn.Modulelist` does this for us."
      ],
      "metadata": {
        "id": "p0HaX6pgxU-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super(). __init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Kr03xOV4vzBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc2tqM3m09RB",
        "outputId": "adf17d7b-9601-4605-a6e7-e8e22f03638a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4z8H9rx1o9A",
        "outputId": "8f93eeaf-faac-4504-ca89-4b7151c3158c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12, 0.96\n",
            "0.07, 0.96\n",
            "0.02, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential"
      ],
      "metadata": {
        "id": "Bdih8pQ3GWlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Sequential` is a convenient class which does the same as the above."
      ],
      "metadata": {
        "id": "IpCscVeUGa8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "metadata": {
        "id": "xkAaVX955IWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZQmCEbSG9A9",
        "outputId": "839a2c55-a485-4b55-bb14-0bdd08bbd666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07, 0.96\n",
            "0.01, 1.00\n",
            "0.01, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optim"
      ],
      "metadata": {
        "id": "KrwtqlaDH1O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer():\n",
        "  def __init__(self, params, lr=0.5):\n",
        "    self.params = list(params)\n",
        "    self.lr = lr\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        p -= p.grad * self.lr\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "CVfzbfipHc7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "metadata": {
        "id": "IozqodAmJ6j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "metadata": {
        "id": "UgHa2QE8KEfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0, n, bs):\n",
        "    s = slice(i, min(n, i+bs))\n",
        "    xb, yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBgbSXr6KPn6",
        "outputId": "6457a9f9-42fa-4afb-a243-9b038ffaa61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13, 0.96\n",
            "0.02, 1.00\n",
            "0.01, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum)"
      ],
      "metadata": {
        "id": "xRigL_EeLo1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "DToijU7DLD9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
        "  return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "10o5To7vL8eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prXOk6lEMSJp",
        "outputId": "8e1a2c33-9b7b-4519-fd8e-c2608286f128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.32, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range (0, n, bs):\n",
        "    s = slice(i, min(n, i+bs))\n",
        "    xb, yb = x_train[s], y_train[s]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3lqwHLmMZTV",
        "outputId": "0b13d715-148c-4cc4-e7c6-41496ff75061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03, 1.00\n",
            "0.06, 0.96\n",
            "0.02, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and DataLoader"
      ],
      "metadata": {
        "id": "yKUkpXksx1Vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "RrlC-EQ4x49S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it's clunky to iterate through minibatches of x and y values separately. Instead let's do these two steps together by introducing a `Dataset` class:"
      ],
      "metadata": {
        "id": "wzu4xSlPx9J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]"
      ],
      "metadata": {
        "id": "aFAzuxHgwsoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "assert len(train_ds) == len(x_train)\n",
        "assert len(valid_ds) == len(y_valid)"
      ],
      "metadata": {
        "id": "wjNTxp5izKFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = train_ds[0:5]\n",
        "assert xb.shape == (5, 28 * 28)\n",
        "assert yb.shape == (5,)\n",
        "xb, yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcioWY6Mz7cK",
        "outputId": "de07023e-8cc8-4699-f1d6-eabf6812a0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()"
      ],
      "metadata": {
        "id": "Vl6ksCWSz82A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0, n, bs):\n",
        "    xb, yb = train_ds[i: min(n,i+bs)]\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmbavlZ0_6X",
        "outputId": "20e05797-3dbd-44f6-f396-f8c8b2afdad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05, 1.00\n",
            "0.02, 1.00\n",
            "0.01, 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "tyTIrwrt2k4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's replace this two line of code:\n",
        "\n",
        "```python\n",
        "for i in range(0, n, bs):\n",
        "  xb, yb = train_ds[i, min(n, i+bs)]\n",
        "  ...\n",
        "```\n",
        "\n",
        "with:\n",
        "```python\n",
        "for xb, yb in train_dl:\n",
        "  ...\n",
        "```"
      ],
      "metadata": {
        "id": "-Z7amrjy2sjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs):\n",
        "    self.ds = ds\n",
        "    self.bs = bs\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs):\n",
        "      yield self.ds[i: i+self.bs]"
      ],
      "metadata": {
        "id": "Wj-mk7LT1Bgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "metadata": {
        "id": "wEu5U8T2483N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(valid_dl))"
      ],
      "metadata": {
        "id": "sUXWnPv_5Frk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r669UL55t6k",
        "outputId": "86c0bb8a-4783-4560-b1f8-cf610dfd36f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA3pDuZM57TW",
        "outputId": "0312f7c7-92a9-46ff-f474-de469ae5b4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2,\n",
              "        1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "0QvV3XGQ7QLC",
        "outputId": "964bae35-744c-48e3-8df6-1c2a9aeb3306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 233
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()"
      ],
      "metadata": {
        "id": "GGZMsh9K7o5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "    report(loss, pred, yb)"
      ],
      "metadata": {
        "id": "lJgIJccg7zwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Qt8Fzb9wBK",
        "outputId": "cee991ba-d287-4cc4-e5a5-0146e3a0a3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07, 0.96\n",
            "0.02, 1.00\n",
            "0.03, 0.98\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.04, grad_fn=<NllLossBackward0>), tensor(0.98))"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random sampling"
      ],
      "metadata": {
        "id": "YFllg_CnAsIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want our training set to be in a random order, and that order should differ each iteretion. But the validation shouldn't be randomized."
      ],
      "metadata": {
        "id": "0mCrq8gbAzJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "I0tmkzM8_qeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler():\n",
        "  def __init__(self, ds, shuffle=False):\n",
        "    self.n = len(ds)\n",
        "    self.shuffle = shuffle\n",
        "  def __iter__(self):\n",
        "    res = list(range(self.n))\n",
        "    if self.shuffle:\n",
        "      random.shuffle(res)\n",
        "    return iter(res)"
      ],
      "metadata": {
        "id": "wGpeim20BGhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice"
      ],
      "metadata": {
        "id": "xls9sEJGEcA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = Sampler(train_ds)"
      ],
      "metadata": {
        "id": "B2zIyBYUEKre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(ss)\n",
        "for o in range(5):\n",
        "  print(next(it))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cX2JjeTEOR3",
        "outputId": "0f646a8a-8fe7-408a-aa73-026ee26ea863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(islice(it, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr_-3Yd-EXpR",
        "outputId": "b7e07e5b-e4e3-4843-fc69-85afc8d01296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss = Sampler(train_ds, shuffle=True)\n",
        "list(islice(ss, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Hr5jvSFdA1",
        "outputId": "2a496981-f44f-4733-be03-81d6518a5617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10150, 2106, 23095, 33440, 10895]"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can use this to create a batch sampler"
      ],
      "metadata": {
        "id": "bLjr4aaJIgax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fastcore.all as fc"
      ],
      "metadata": {
        "id": "RxZbqVJmFrjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchSampler():\n",
        "  def __init__(self, sampler, bs, drop_last=False):\n",
        "    # sampler, bs, drop_last = self.sampler, self.bs, self.drop_last\n",
        "    fc.store_attr()\n",
        "  def __iter__(self):\n",
        "    yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
      ],
      "metadata": {
        "id": "X-5VnnJKIm4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchs = BatchSampler(ss, 5)\n",
        "list(islice(batchs, 6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKUQlxamJSoD",
        "outputId": "3cde66aa-5450-4063-af4d-77557770a106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[55708, 29060, 33261, 10000, 34969],\n",
              " [1566, 37503, 37817, 9023, 52377],\n",
              " [45649, 39701, 8253, 32753, 45098],\n",
              " [24732, 4693, 41939, 10793, 33664],\n",
              " [51267, 44280, 45696, 25214, 26457],\n",
              " [51215, 40490, 50453, 29359, 31126]]"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(b):\n",
        "  xs, ys = zip(*b)\n",
        "  return torch.stack(xs), torch.stack(ys)"
      ],
      "metadata": {
        "id": "1lut9qkSMxRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, batchs, collate_fn=collate):\n",
        "    fc.store_attr()\n",
        "  def __iter__(self):\n",
        "    yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
      ],
      "metadata": {
        "id": "3fbCHIhVKLzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o = next(iter(train_samp))\n",
        "# p = [train_ds[i] for i in o]\n",
        "# xs, ys = zip(*p)\n",
        "# torch.stack(xs)"
      ],
      "metadata": {
        "id": "tpEPt6QPS8Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
        "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
      ],
      "metadata": {
        "id": "l0Uw_LaZM8x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, train_samp)\n",
        "valid_dl = DataLoader(valid_ds, valid_samp)"
      ],
      "metadata": {
        "id": "kK5Ywr0JOZn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28, 28))\n",
        "yb[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5TVZI1IyPKHX",
        "outputId": "e7322e6b-5b9d-464f-dd42-6011bb541dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 252
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiprocessing DataLoader"
      ],
      "metadata": {
        "id": "TmCamrPKXakU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing just like in pytorch means that\n",
        "``` python\n",
        "self.ds[i]\n",
        "```\n",
        "It can be run in parallel for multiple items. So that code can be opening a jpeg, rotating and flipping it"
      ],
      "metadata": {
        "id": "n5B75LCGQ4d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "from fastcore.basics import store_attr"
      ],
      "metadata": {
        "id": "bFxoHw3_Zmef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[[3, 6, 8, 1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxCU-9EHPYGP",
        "outputId": "e5e4576b-6ac5-44f3-fdc7-9bc272ede1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.__getitem__([3, 6, 8, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvSKTlwiYAEQ",
        "outputId": "3c06315a-93d4-4f04-9059-79b0748772bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for o in map(train_ds.__getitem__, ([3, 6], [8, 1])):\n",
        "  print(o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_6--PeeYPbH",
        "outputId": "1f19fafc-62d8-4712-d36e-8a976924201b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, batchs, n_workers=1, collate_fn=collate):\n",
        "    fc.store_attr()\n",
        "  def __iter__(self):\n",
        "    with mp.Pool(self.n_workers) as ex:\n",
        "      yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
      ],
      "metadata": {
        "id": "88-pHP4xYoik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
        "it = iter(train_dl)"
      ],
      "metadata": {
        "id": "0jk2CHezdq20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb,yb = next(it)\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa0eoxxoeTWw",
        "outputId": "54bcfdf4-da2d-4cfb-aa3f-08c0180d937a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 784]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch DataLoader"
      ],
      "metadata": {
        "id": "fbAb-R1Uex3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils. data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "metadata": {
        "id": "NASBjq07eZ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samp = BatchSampler(RandomSampler(train_ds), bs)\n",
        "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs)"
      ],
      "metadata": {
        "id": "uRgQfSK_fHA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
      ],
      "metadata": {
        "id": "7f1f42anflZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV27eEUwfpEI",
        "outputId": "a4d409dd-b0e7-4a76-d64c-4c046736a91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07, 0.98\n",
            "0.11, 0.96\n",
            "0.01, 1.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.04, grad_fn=<NllLossBackward0>), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch can auto-generate the Batchsampler for us instead of manually using the batchsampler repeatedly."
      ],
      "metadata": {
        "id": "OoquTFrPjrFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "metadata": {
        "id": "r6jJUD22gp_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "tieRsuyXkcE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duJToFXmoMmp",
        "outputId": "01ebb59a-8e5e-40fd-9a29-716bb0e4a3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19, 0.94\n",
            "0.10, 0.94\n",
            "0.04, 1.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.21, grad_fn=<NllLossBackward0>), tensor(0.94))"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
      ],
      "metadata": {
        "id": "oAcrKtkgoWZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_dl))\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Dp4Et9qmRw",
        "outputId": "99b8d3a5-e3d8-445d-e3c4-0fe05e302cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "Q-rfdGopq9vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use validation set to identify when you are overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "o-5SXWKrrCic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc,count = 0.,0.,0\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                n = len(xb)\n",
        "                count += n\n",
        "                tot_loss += loss_func(pred,yb).item()*n\n",
        "                tot_acc  += accuracy (pred,yb).item()*n\n",
        "        print(epoch, tot_loss/count, tot_acc/count)\n",
        "    return tot_loss/count, tot_acc/count"
      ],
      "metadata": {
        "id": "NgWczt9YquH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "  return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "          DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "metadata": {
        "id": "A_X3znYgyn1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iMRboMrzyAE",
        "outputId": "d8ec27ee-127b-4ef1-bc07-098eaff42764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.13149705038871617 0.9585000079870224\n",
            "1 0.11669149911729619 0.964200005531311\n",
            "2 0.10573875582311303 0.9686000043153763\n",
            "3 0.09378742052533198 0.9737000095844269\n",
            "4 0.10211027007841039 0.9712000089883804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of everything covered in this notebook:\n",
        "\n",
        "- Loaded the MNIST dataset and prepared the data for training.\n",
        "- Built a simple two-layer neural network (MLP) from scratch using basic PyTorch operations.\n",
        "- Implemented the forward and backward passes manually for the MLP.\n",
        "- Compared the manually calculated gradients with PyTorch's autograd to verify correctness.\n",
        "- Refactored the model by creating classes for layers (`Relu`, `Lin`, `Mse`, and `Model`) to make the code more modular and object-oriented.\n",
        "- Further refactored the layer classes to inherit from a base `Module` class, mimicking PyTorch's `nn.Module`.\n",
        "- Replaced the custom layers with PyTorch's built-in `nn.Linear` and `nn.ReLU` to leverage autograd.\n",
        "- Switched from Mean Squared Error (MSE) loss to Cross-Entropy loss, which is more suitable for multi-class classification problems like MNIST.\n",
        "- Implemented and tested the `log_softmax` and `logsumexp` functions, and compared them with PyTorch's implementations.\n",
        "- Introduced the concept of negative likelihood loss (`nll`) and verified it against PyTorch's `F.nll_loss` and `F.cross_entropy`.\n",
        "- Set up a basic training loop with mini-batches.\n",
        "- Implemented an accuracy metric to evaluate the model's performance.\n",
        "- Performed a basic training run using the implemented training loop, loss function, and optimizer (manual gradient updates).\n",
        "- Explored how PyTorch automatically registers layers and parameters in `nn.Module`.\n",
        "- Demonstrated how to manually register modules using `add_module` and `nn.ModuleList`.\n",
        "- Showcased the convenience of `nn.Sequential` for building models.\n",
        "- Implemented a custom `Optimizer` class and compared it with PyTorch's `optim.SGD`.\n",
        "- Introduced the `Dataset` class to handle data and labels together.\n",
        "- Developed a custom `DataLoader` to iterate through mini-batches.\n",
        "- Incorporated random sampling and batching with `Sampler` and `BatchSampler`.\n",
        "- Briefly touched upon multiprocessing with `DataLoader`.\n",
        "- Utilized PyTorch's built-in `DataLoader`, `RandomSampler`, and `SequentialSampler`.\n",
        "- Implemented a validation loop to monitor training and prevent overfitting.\n",
        "- Created a helper function `get_dls` to easily get DataLoaders for training and validation sets.\n",
        "- Ran a complete training and validation cycle using the refined components."
      ],
      "metadata": {
        "id": "8PajHen20Nm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get some dataset from Hugging Face to work with..."
      ],
      "metadata": {
        "id": "11B4l3_R_phw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AKoS4ga7cv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}